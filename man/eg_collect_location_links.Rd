% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/grocer_funcs.R
\name{eg_collect_location_links}
\alias{eg_collect_location_links}
\alias{eg_collect_stores_details}
\alias{eg_collect_categories}
\alias{eg_collect_subcategories}
\alias{eg_collect_items}
\title{Collect elgrocer data}
\usage{
eg_collect_location_links(remDr = remDr, url = "https://www.elgrocer.com")

eg_collect_stores_details(
  remDr = remDr,
  links_to_use,
  sleep_min = 0,
  sleep_max = 1,
  url = "https://www.elgrocer.com"
)

eg_collect_categories(
  remDr = remDr,
  links_to_use,
  sleep_min = 0,
  sleep_max = 1,
  url = "https://www.elgrocer.com"
)

eg_collect_subcategories(
  remDr = remDr,
  links_to_use,
  sleep_min = 0,
  sleep_max = 1,
  url = "https://www.elgrocer.com"
)

eg_collect_items(remDr, links_to_use, sleep_min = 0, sleep_max = 1)
}
\arguments{
\item{remDr}{Remote client driver}

\item{url}{elgrocer url}

\item{links_to_use}{Subcategory links}

\item{sleep_min}{Minimum time to suspend executing R expressions}

\item{sleep_max}{Maximum time to suspend executing R expressions}
}
\value{
\code{*_location_links}:Tibble with the URL for each location

\code{*_store_details}: Tibble with store links

\code{*_categories}: Tibble with category links

\code{*_subcategories}: Tibble with subcategory links

\code{*_items}: Tibble with product details
}
\description{
The 5 \code{eg_collect_*} functions chronologically scrape the
\emph{elgrocer} website and return the data indicated by each function name.
}
\section{Note}{

In order to play nice with the website, the scraper functions have
a built in 'sleep functionality'. This means that the functions will
suspend execution (i.e., go to sleep) for a random time interval, usually
less than 11 seconds whenever the sleep function, \emph{nytnyt}, is
called. See the \emph{vignette} for more information.

These functions are verbose, allowing the user to get a sense of progress.
}

\examples{
\dontrun{
# Initiate server
remDr <- RSelenium::rsDriver(port = netstat::free_port(),
browser = "firefox", verbose = FALSE)$client

# Collect all location links
grocer_location <- eg_collect_location_links(remDr = remDr, url = "https://www.elgrocer.com")

# Collect store details from 5 locations
grocer_store <- eg_collect_stores_details(remDr, grocer_location$location_link[1:5])

# Collect categories from 3 stores
grocer_category <- eg_collect_categories(remDr, grocer_store$store_link[1:3])

# Collect subcategories from 3 categories
random_category_links <- sample(1:length(grocer_category$category_link),
3, replace = FALSE)
grocer_subcategory <- eg_collect_subcategories(grocer_category$category_link[random_category_links])

# Collect product data from 2 subcategories
random_subcategory_links <- sample(1:length(grocer_subcategory$subcategory_link),
2, replace = FALSE)
grocer_item <- eg_collect_items(grocer_subcategory$subcategory_link[random_subcategory_links])

# Close the server
remDr$close()
gc(remDr)
rm(remDr)
}
}
\seealso{
\code{\link{oc_collect_categories}} for elgrocer data collection.
\code{\link{nytnyt}} for sleep functionality.
}
